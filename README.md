# Maestr√≠a en Inteligencia Artificial Aplicada 

## Curso: Proyecto Integrador (Grupo 10) 

<br />

### Profesor titular  
#### Dra. Grettel Barcel√≥ Alonso 
#### Dr. Luis Eduardo Falc√≥n Morales  
<br />

<table>
<tr>
    <th colspan="2">Equipo 19: Los Californios I</th>
</tr>
<tr>
    <td>Ernesto Zapata Garza</td><td>A00915255</td>
</tr>
<tr>
    <td>Rafael Garc√≠a Dom√≠nguez</td><td>A01328974</td>
</tr>
<tr>
    <td>Erik L√≥pez Hern√°ndez</td><td>A00458875</td>
</tr>
</table>
<br />


<hr />

## Los Californios I - Producci√≥n de tr√°iler con Inteligencia Artificial Generativa
Este repositorio contiene las diferentes fases entregables para el proyecto Los Californios donde el objetivo principal es generar un tr√°iler de la serie Los Californios, utilizando el gui√≥n adaptado de la obra literaria hom√≥nima.

<hr />

## Avance 1. An√°lisis exploratorio de datos
##### 4 de mayo de 2025

### üìÅ Contenido del repositorio
- üìò Libreta de Jupyter Notebook para el an√°lisis lexicogr√°fico. [Avance1_Equipo19.ipynb](notebooks/Avance1_Equipo19.ipynb)
- üìò Libreta de Jupyter Notebook para el an√°lisis de escenas, personajes y emociones. [Avance1.19.ipynb](notebooks/Avance1.19.ipynb)
- üìù Se incluyen dos archivos de texto como marcadores de posici√≥n, LosCaliforniosBook.txt y LosCaliforniosScript.txt, los cuales deben ser reemplazados en el ambiente local con los archivos que contienen la informaci√≥n real.
- üìä Se incluye un gr√°fico de nube de palabras con algunos de los resultados del an√°lisis lexicogr√°fico. [WordOfClouds.png](outputs/visualizations/WordOfClouds.png)

#### Notas: 
- Por cuestiones de privacidad con el autor, se ha decidido no adjuntar el contenido del libro y el gui√≥n en el repositorio p√∫blico.
- La libreta con el an√°lisis de escenas, personajes y emociones requiere de un TOKEN de Hugging Face para poder ejecutar correctamente.

### üí° Conclusiones

El an√°lisis exploratorio de datos (EDA) realizado sobre el gui√≥n completo de la serie *Los Californios*, a trav√©s de herramientas de Procesamiento de Lenguaje Natural (NLP), permiti√≥ caracterizar cuantitativamente elementos narrativos complejos como la aparici√≥n de personajes, la carga emocional de las escenas y la estructuraci√≥n tem√°tica del relato. Esta aproximaci√≥n representa una aplicaci√≥n relevante de la inteligencia artificial al an√°lisis de textos dram√°ticos con fines tanto anal√≠ticos como creativos.

Desde el punto de vista t√©cnico, se implementaron dos enfoques complementarios:

1. El primero, centrado en t√©cnicas cl√°sicas de procesamiento textual (tokenizaci√≥n, eliminaci√≥n de stopwords, an√°lisis de frecuencias), permiti√≥ obtener un mapa l√©xico b√°sico del corpus, visualizar los t√©rminos predominantes por cap√≠tulo mediante nubes de palabras, y construir un vocabulario que sienta las bases para an√°lisis posteriores de contenido.
2. El segundo, de mayor complejidad sem√°ntica, integr√≥ herramientas de PLN modernas como spaCy, transformers, y sentence-transformers, permitiendo:
   - La identificaci√≥n autom√°tica de entidades nombradas, particularmente personajes, mediante modelos entrenados en espa√±ol.
   - La detecci√≥n de emociones por escena utilizando un clasificador multiling√ºe sobre oraciones traducidas al ingl√©s.
   - La agrupaci√≥n de escenas en cl√∫steres tem√°ticos usando embeddings sem√°nticos y KMeans, lo cual revel√≥ estructuras narrativas latentes no evidentes en una lectura lineal del gui√≥n.

Entre los hallazgos m√°s relevantes se destacan los siguientes:
  - Algunos personajes concentran una cantidad desproporcionada de escenas, lo cual sugiere centralidad narrativa y posibles desequilibrios en la construcci√≥n del conflicto dram√°tico.
  - Las emociones m√°s frecuentes detectadas fueron tristeza, alegr√≠a moderada y miedo, lo cual indica una narrativa cargada de tensi√≥n emocional que acompa√±a a los eventos hist√≥ricos y personales que retrata la serie.
  - El an√°lisis por clustering revel√≥ cinco n√∫cleos narrativos principales, relacionados con tem√°ticas como colonizaci√≥n, resistencia ind√≠gena, conflicto religioso, construcci√≥n de identidad y transici√≥n cultural.
  - La longitud de las escenas mostr√≥ una alta varianza, con algunas escenas concentrando di√°logos extensos y otras funcionando como transiciones, lo cual puede correlacionar con la evoluci√≥n del ritmo narrativo.

Estas conclusiones confirman que el uso de modelos de IA generativa y NLP no solo es viable, sino altamente efectivo para estudiar obras narrativas desde una perspectiva anal√≠tica cuantitativa. Adem√°s, sientan las bases para una fase posterior de generaci√≥n creativa asistida por IA, donde estos insumos podr√≠an alimentar modelos de generaci√≥n de gui√≥n, personalizaci√≥n de experiencias narrativas o an√°lisis estil√≠stico comparado con otras series hist√≥ricas.

<hr />

## Avance 2. Ingenier√≠a de caracter√≠sticas
##### 11 de mayo de 2025

### üìÅ Contenido del repositorio
- üìò Libreta de Jupyter Notebook para la ingenier√≠a de caracter√≠sticas. [Avance2.19.ipynb](notebooks/Avance2.19.ipynb)

#### Notas: 
- Por cuestiones de privacidad con el autor, se ha decidido no adjuntar el contenido del libro y el gui√≥n en el repositorio p√∫blico.
- La libreta con la ingenier√≠a de caracter√≠sticas requiere de un TOKEN de Hugging Face para poder ejecutar correctamente.

### üí° Conclusiones

Durante esta fase del proyecto se llevaron a cabo actividades para transformar el guion narrativo de <i>Los Californios</i> en un conjunto de variables estructuradas.

- <b>Generaci√≥n de caracter√≠sticas narrativas</b>: A partir del an√°lisis textual, se construyeron variables derivadas como la longitud de escena (n√∫mero de palabras), n√∫mero de personajes por escena y codificaci√≥n emocional usando modelos de lenguaje. Esto permiti√≥ cuantificar elementos cualitativos del guion y facilitar su procesamiento automatizado.
- <b>Codificaci√≥n y representaci√≥n de emociones</b>: Se aplic√≥ codificaci√≥n <i>one-hot</i> sobre la variable de emoci√≥n principal para representar categor√≠as como joy, anger o sadness de froma num√©rica, permitiendo su incorporaci√≥n en modelos de agrupamiento, visualizaci√≥n y selecci√≥n de escenas para el tr√°iler.
- <b>Normalizaci√≥n de variables</b>: Se utiliz√≥ <i>Min-Max Scaling</i> para normalizar variables como longitud de escenas y cantidad de personajes, asegurando que tuvieran el mismo rango de influcencia en t√©cnicas posteriores de reducci√≥n de dimensionalidad y clustering.
- <b>Selecci√≥n y extracci√≥n de caracter√≠sticas</b>: Se emple√≥ el m√©todo de umbral de varianza para filtrar variables irrelevantes y se aplic√≥ An√°lisis de Componentes Principales (PCA) para reducir la dimensionalidad del conjunto, facilitando la interpretaci√≥n visual de agrupaciones tem√°ticas entre escenas.
- <b>Similitud sem√°ntica entre escenas</b>: A trav√©s de embeddings generados con SentenceTransformer y la m√©trica de similitud del coseno, se construy√≥ una matriz de similitud entre escenas del guion. Esta herramienta permiti√≥ identificar escenas con tem√°ticas o emociones similares, apoyando la selecci√≥n coherente de fragmentos narrativos para la generaci√≥n del tr√°iler.
- <b>Valor creativo agregado</b>: Se exploraron actividades opcionales como un benchmark subjetivo entre herramientas de generaci√≥n audiovisual (Pika Labs, Runway, Sora, Kaiber), evaluaci√≥n comparativa de voces sint√©ticas (ElementLabs, Play.ht, Coqui), y simulaci√≥n de storyboard visual, aportando un enfoque t√©nico y pr√°ctico que vincula la ingenier√≠a de caracter√≠sticas con decisiones reals de producci√≥n narrativa.

Estas actividades permitieron transformar datos textuales crudos en insumos listos para ser utilizados en etapas posteriores del proyecto, especialmente en la generaci√≥n automatizada del tr√°iler. La aplicaci√≥n de t√©cnicas propias de la ingenier√≠a de caracter√≠sticas fue adaptada al contexto narrativo con resultados √∫tiles, coherentes y justificados metodol√≥gicamente seg√∫n los principios de CRISP-ML.

<hr />

## Avance 3. Baseline
##### 18 de mayo de 2025

### üìÅ Contenido del repositorio
- üìò Libreta de Jupyter Notebook para el modelo base. [Avance3.19.ipynb](notebooks/Avance3.19.ipynb)

#### Notas: 
- Por cuestiones de privacidad con el autor, se ha decidido no adjuntar el contenido del libro y el gui√≥n en el repositorio p√∫blico.
- La libreta con la ingenier√≠a de caracter√≠sticas requiere de un TOKEN de Hugging Face para poder ejecutar correctamente.

### üí° Conclusiones

Durante esta fase del proyecto se llevaron a cabo actividades para identificar un posible modelo base para usar el guion de <i>Los Californios</i> y generar los prompts necesarios para las herramientas de Inteligencia Artificial Generativa.

<br/>

<b>¬øQu√© algoritmo se puede utilizar como baseline para predecir la variable objetivo?</b>

Se utiliz√≥ Regresi√≥n Log√≠stica como modelo baseline para predecir la emoci√≥n principal de cada escena a partir de su contenido textual. Esta elecci√≥n se justifica porque:

- Es un modelo lineal y eficiente, com√∫n en tareas de clasificaci√≥n multiclase con datos escasos.
- Funciona bien con representaciones TF-IDF, que capturan la importancia relativa de las palabras.
- Permite interpretabilidad directa de las caracter√≠sticas relevantes.

Aunque se consider√≥ usar tambi√©n DummyClassifier con la estrategia "most_frequent", los resultados del modelo de regresi√≥n log√≠stica mostraron que supera ligeramente ese m√≠nimo (accuracy ~0.61), lo cual sugiere que el texto contiene cierta se√±al √∫til para predecir la emoci√≥n, aunque limitada.

<br />

<b>¬øSe puede determinar la importancia de las caracter√≠sticas para el modelo generado?</b>

S√≠, tras aplicar TF-IDF vectorization, se seleccionaron las 10 palabras m√°s influyentes usando la t√©nica SelectBest con chi-cuadrado. Las palabras fueron:

['carpentier', 'hereje', 'impuesto', 'inquisici√≥n', 'insulta', 'inuk', 'josefa', 'pedro', 'pregonero', 'virrey']

Esto demuestra que ciertos t√©rminos est√°n asociados a contextos emocionales, especialmente hist√≥ricos o de conflicto. Este an√°lisis:

- Permite eliminar t√©rminos irrelevantes o redundantes en futuros modelos.
- Ayuda a dise√±ar filtros tem√°ticos para escenas.
- Aporta interpretabilidad narrativa al proceso de selecci√≥n de escenas.

<br />

<b>¬øEl modelo est√° subajustando o sobreajustando los datos de entrenamiento?</b>

Los resultados indican que el modelo sufre de subajustes:

- F1 ponderado en prueba: 0.46
- F1 en validaci√≥n cruzada (5-fold): 0.33
- La mayor√≠a de las clases minoritarias tienen F1 = 0.00, indicando que el modelo no logra aprender patrones significativos m√°s all√° de la clase dominante (fear).
- Accuracy enga√±osamente alta (0.61), pero s√≥lo porque predice bien una sola clase.

El modelo es demasiado simple o los datos demasiado dispersos. Hay oportunidad de mejorar usando:

- Embeddings sem√°nticos
- Rebalanceo de clases
- Modelos no lineales

<br />

<b>¬øCu√°l es la m√©trica adecuada para este problema de negocio?</b>

Dado que se trata de una clasificaci√≥n multiclase con clases desbalanceadas, la m√©trica m√°s adecuada es el:

- F1-score macro: da peso igual a todas las clases y permite evaluar el modelo en t√©rminos de precisi√≥n y recall por emoci√≥n, no s√≥lo por volumen.

Aunque accuracy puede reportarse, no es confiable por s√≠ sola en este contexto, ya que puede estar sesgada hacia la clase m√°s frecuente.

<br />

<b>¬øCu√°l deber√≠a ser el desempe√±o m√≠nimo por obtener?</b>

El desempe√±o m√≠nimo aceptable es que supere al modelo aleatorio (DummyClassifier) y demuestre capacidad para distinguir al menos dos o m√°s clases de emoci√≥n con una F1 significativa. En este caso:

- DummyClassifier esperar√≠a un F1 ponderado cercano a 0.25-0.30 si predice siempre la clase m√°s com√∫n.
- El modelo actual obtiene F1 ponderado ‚âà 0.46, lo que indica una ligera ventaja, pero a√∫n insuficiente para selecci√≥n narrativa precisa.

Se podr√≠a considerar utilizar embeddings (SentenceTransformer) y clasificadores m√°s expresivos como RandomForest, SVM o XGBoost, o modelos neuronales ligeros para capturar relaciones sem√°nticas m√°s profundas.

El objetivo final es, basado en el modelo entrenado, poder seleccionar autom√°ticamente las 2 o 3 escenas m√°s representativas de cada emoci√≥n, para poder generar las entradas directas para herramientas de generaci√≥n de video como Pika Labs, Runway o ElevenLabs para voz.

<br />

## Comparativo de herramientas de Inteligencia Artificial Generativa

<br />

üñºÔ∏è **Generaci√≥n de Video**

| Herramienta        | Tipo de salida         | Fortalezas                            | Limitaciones                    |
| ------------------ | ---------------------- | ------------------------------------- | ------------------------------- |
| **Pika Labs**      | Video corto por prompt | Cinematograf√≠a, movimientos de c√°mara | Sin control de rostro o audio   |
| **Runway ML**      | Video estilizado       | Integraci√≥n con texto y audio         | Requiere GPU para exportaciones |
| **Kaiber**         | Video tipo videoclip   | Est√©tica creativa, animaci√≥n fluida   | No permite sincronizar di√°logos |
| **Sora (OpenAI)**  | Ultra realismo (beta)  | F√≠sicas realistas, escenas complejas  | No disponible al p√∫blico a√∫n    |
| **Gen-2 (Runway)** | Text-to-video avanzada | Control por imagen gu√≠a + texto       | Pago y licencia limitada        |

<br />

üé∂ **Generaci√≥n de M√∫sica Ambiental**
| Herramienta        | Caracter√≠sticas                    | Estilos disponibles     | Control emocional |
| ------------------ | ---------------------------------- | ----------------------- | ----------------- |
| **Soundraw\.io**   | M√∫sica generada por categor√≠a      | Cine, acci√≥n, drama     | Muy alto          |
| **AIVA**           | Composici√≥n asistida por IA        | Orquestal, piano, √©pico | Medio             |
| **Epidemic Sound** | Biblioteca musical curada por IA   | Muy variado             | Bajo              |
| **Suno.ai (v3)**   | Texto a m√∫sica o canci√≥n narrativa | Narrativa, pop, vocales | Medio             |

<br />

üó£Ô∏è **Generaci√≥n de Di√°logos y Personajes Animados**
| Herramienta     | Funcionalidad principal              | Control de emoci√≥n/voz    | Sincronizaci√≥n visual      |
| --------------- | ------------------------------------ | ------------------------- | -------------------------- |
| **ElevenLabs**  | Voz ultra realista multiling√ºe       | Excelente (matices altos) | Audio sin video            |
| **Play.ht**     | Voces narrativas y sint√©ticas        | Buena                     | S√≥lo audio                 |
| **Coqui.ai**    | Texto a voz emocional, open source   | Medio-alto                | Sin video integrado        |
| **D-ID Studio** | Video animado de rostro con voz      | Muy bueno para busto      | Sin cuerpo completo        |
| **HeyGen**      | Avatares 3D con di√°logo sincronizado | Muy realista              | Alto costo y branding fijo |

<hr />

## Avance 4 ‚Äì Evaluaci√≥n y Comparaci√≥n de Modelos
##### 25 de mayo de 2025

### üìÅ Contenido del repositorio
- üìò Libreta de Jupyter Notebook para el modelo base. [Avance4.19.ipynb](notebooks/Avance4.19.ipynb)

#### Notas: 
- Por cuestiones de privacidad con el autor, se ha decidido no adjuntar el contenido del libro y el gui√≥n en el repositorio p√∫blico.
- La libreta con la ingenier√≠a de caracter√≠sticas requiere de un TOKEN de Hugging Face para poder ejecutar correctamente.

### üéØ Objetivo del avance

En este avance, se construyeron y evaluaron **6 modelos de clasificaci√≥n individual** para predecir las **emociones presentes en las escenas del guion ‚ÄúLos Californios‚Äù**. Los modelos implementados abarcaron algoritmos lineales, probabil√≠sticos y m√©todos m√°s complejos basados en √°rboles y distancias.

La comparaci√≥n se realiz√≥ con base en m√©tricas clave:

- **Accuracy**
- **F1-macro**
- **F1 ponderado**
- **Tiempo de entrenamiento**

Esto permiti√≥ evaluar de forma integral la idoneidad de cada modelo para el problema planteado.

---

### üìä Resultados por modelo

#### üî∏ XGBoost
- **F1-macro:** 0.2156
- **Accuracy:** 51.56%
- **Tiempo de entrenamiento:** 4.27 s
- ‚úÖ Mejor desempe√±o general antes del ajuste.
- ‚úÖ Robusto y eficaz con relaciones complejas.
- ‚ùó Costo computacional relativamente alto.

#### üî∏ KNeighborsClassifier
- **F1-macro:** 0.1639
- **Accuracy:** 42.19%
- **Tiempo de entrenamiento:** 0.005 s
- ‚úÖ Muy eficiente y r√°pido.
- ‚úÖ Buena interpretaci√≥n de similitudes TF-IDF.
- üîÅ Mejor√≥ tras el ajuste fino (ver m√°s abajo).

### üî∏ Support Vector Classifier (SVC)
- **F1-macro:** 0.1624
- **Accuracy:** 60.94%
- **Tiempo de entrenamiento:** 0.13 s
- üî∏ Buen accuracy, pero bajo F1.
- ‚ùó Sensible a hiperpar√°metros.

#### üî∏ Random Forest
- **F1-macro:** 0.1549
- **Accuracy:** 59.38%
- **Tiempo de entrenamiento:** 0.94 s
- üî∏ Capacidad para relaciones no lineales.
- ‚ùó Bajo rendimiento comparativo.

#### üî∏ Multinomial Naive Bayes (MNB)
- **F1-macro:** 0.1262
- **Accuracy:** 60.94%
- **Tiempo de entrenamiento:** 0.003 s
- ‚úÖ Ultra r√°pido.
- ‚ùó Pobre en relaciones sem√°nticas complejas.

#### üî∏ Logistic Regression
- **F1-macro:** 0.1262
- **Accuracy:** 60.94%
- **Tiempo de entrenamiento:** 1.65 s
- üî∏ F√°cil de interpretar.
- ‚ùó Superado en rendimiento por otros modelos.

---

### üß™ Ajuste de modelos seleccionados

#### ‚ú≥Ô∏è XGBoost (ajustado)
- **F1-macro:** 0.1977 (ligera ca√≠da)
- **Mejores hiperpar√°metros:**
  - `learning_rate`: 0.01
  - `max_depth`: 10
  - `n_estimators`: 50
  - `subsample`: 1
- ‚ùó No logr√≥ mejorar su score original.

#### ‚ú≥Ô∏è KNeighborsClassifier (ajustado)
- **F1-macro:** **0.2426** ‚úÖ
- **Mejores hiperpar√°metros:**
  - `n_neighbors`: 7
  - `weights`: 'distance'
  - `metric`: 'euclidean'
- ‚úÖ Mayor mejora tras ajuste.
- ‚úÖ Mejor modelo final.

---

### üèÅ Modelo final seleccionado: `KNeighborsClassifier` (ajustado)

#### ‚úÖ Justificaci√≥n t√©cnica
- Mayor F1-macro tras el ajuste.
- Bajo tiempo de entrenamiento.
- Capacidad de interpretar relaciones sem√°nticas v√≠a TF-IDF.

#### üé¨ Justificaci√≥n narrativa
- Favorece la agrupaci√≥n de escenas por emoci√≥n similar.
- Ideal para preselecci√≥n narrativa en la construcci√≥n del tr√°iler.
- Balance entre eficiencia, rendimiento y claridad interpretativa.

---

### ‚úÖ Conclusi√≥n

La evaluaci√≥n y comparaci√≥n de los modelos permitieron seleccionar al **KNeighborsClassifier ajustado** como modelo final para predecir emociones narrativas en escenas.

Esta decisi√≥n se fundamenta tanto en m√©tricas de desempe√±o como en:
- Su capacidad para capturar relaciones sem√°nticas clave.
- Su tiempo de entrenamiento m√≠nimo.
- Su alineaci√≥n con los objetivos creativos del proyecto.

El modelo final est√° preparado para integrarse en la fase de automatizaci√≥n de selecci√≥n de escenas para el tr√°iler.
